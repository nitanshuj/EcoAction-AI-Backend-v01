# ğŸŒ± EcoAction AI

<p align="center">
   <img src="images/cover_image_2.jpg" alt="EcoAction AI Cover" style="max-width: 100%; height: auto; border-radius: 12px; box-shadow: 0 4px 16px rgba(0,0,0,0.15); margin-bottom: 24px;" />
</p>

<p align="center">
  <strong>Personalized AI-Powered Climate Action Platform</strong>
</p>

<p align="center">
  <img src="https://img.shields.io/badge/Python-3.10-blue?style=flat-square&logo=python" alt="Python Version" />
  <img src="https://img.shields.io/badge/Streamlit-1.48+-red?style=flat-square&logo=streamlit" alt="Streamlit" />
  <img src="https://img.shields.io/badge/CrewAI-0.159+-green?style=flat-square" alt="CrewAI" />
  <img src="https://img.shields.io/badge/Supabase-2.18+-blue?style=flat-square&logo=supabase" alt="Supabase" />
</p>

---

## ğŸ¯ What Does This App Do?

EcoAction AI transforms climate awareness into action through personalized sustainability coaching. Using advanced AI analysis, it calculates individual carbon footprints, identifies high-impact reduction opportunities, and delivers customized weekly challenges. The platform bridges the gap between environmental intention and measurable action through data-driven insights.

## ğŸ” Why Was There a Need?

Most people want to help the environment but don't know where to start or which actions matter most. Generic sustainability advice wastes effort on low-impact activities while missing major reduction opportunities for each individual's unique lifestyle.

## ğŸ¤– AI Agent Integration & LLM Architecture

EcoAction AI leverages a sophisticated three-agent system powered by GPT-4.1-nano through the AIML API, orchestrated via CrewAI framework:

**Agent 1 (Profiler):** Analyzes onboarding data to create enriched user profiles with psychographic insights, identifying personal motivations, barriers, and key carbon reduction levers tailored to individual lifestyles.

**Agent 2 (Analyst):** Performs quantitative carbon footprint analysis using emission factors, validates reduction opportunities, and generates personalized insights that connect emissions data with user psychology for maximum behavioral impact.

**Agent 3 (Planner):** Creates actionable weekly sustainability challenges combining daily habits with long-term goals, adapting recommendations based on user progress and maintaining engagement through personalized coaching.

Each agent uses structured JSON outputs with Pydantic validation, ensuring data integrity and seamless workflow integration for reliable, scalable AI-driven sustainability guidance.

## ğŸ› ï¸ Tech Stack

### **Core Framework**
- **Frontend:** Streamlit 1.48+ (Interactive web interface)
- **Backend:** Python 3.10 with FastAPI
- **Database:** Supabase (PostgreSQL with real-time capabilities)
- **Authentication:** Supabase Auth with secure session management

### **AI & Machine Learning**
- **LLM Provider:** AIML API (GPT-4.1-nano)
- **Agent Framework:** CrewAI 0.159+ (Multi-agent orchestration)
- **Data Validation:** Pydantic 2.0+ (Structured outputs)
- **Carbon Analysis:** Custom emission factor calculations

### **Development & Deployment**
- **Package Manager:** UV (Ultra-fast Python package manager)
- **Environment Management:** Python virtual environments
- **Testing:** Pytest with async support
- **Code Quality:** Black, Ruff, MyPy, Bandit
- **Version Control:** Git with structured workflows

### **Key Dependencies**
```python
streamlit>=1.48.1          # Web interface
crewai>=0.159.0           # AI agent framework
supabase>=2.18.1          # Database & auth
pydantic>=2.0.0           # Data validation
openai>=1.100.2           # LLM integration
pandas>=2.3.1             # Data analysis
```

## ğŸ“‚ Current File Structure

```
ecoaction_ai_v01/
â”œâ”€â”€ app.py                     # Main Streamlit application
â”œâ”€â”€ pyproject.toml            # Project dependencies & config
â”œâ”€â”€ uv.lock                   # Dependency lock file
â”œâ”€â”€ README.md                 # Project documentation
â”œâ”€â”€ .env                      # Environment variables (not in repo)
â”‚
â”œâ”€â”€ agent/                    # AI Agent System
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ agents.py            # Agent definitions (Profiler, Analyst, Planner)
â”‚   â”œâ”€â”€ crew.py              # Agent workflow orchestration
â”‚   â”œâ”€â”€ tasks.py             # Task definitions for each agent
â”‚   â”œâ”€â”€ models.py            # Pydantic models for data validation
â”‚   â”œâ”€â”€ utils.py             # Agent utility tools
â”‚   â””â”€â”€ __pycache__/         # Python cache files
â”‚
â”œâ”€â”€ data_model/              # Database & Authentication
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ auth.py              # User authentication logic
â”‚   â”œâ”€â”€ database.py          # Database operations & queries
â”‚   â”œâ”€â”€ supabase_client.py   # Supabase client configuration
â”‚   â””â”€â”€ __pycache__/         # Python cache files
â”‚
â”œâ”€â”€ pages/                   # Streamlit Multi-page App
â”‚   â”œâ”€â”€ 1_auth.py           # Authentication & user management
â”‚   â”œâ”€â”€ 2_onboarding.py     # User profiling & agent workflows
â”‚   â”œâ”€â”€ 3_dashboard.py      # Results display & progress tracking
â”‚   â””â”€â”€ 4_score_calculated.py # Carbon footprint visualization
â”‚
â”œâ”€â”€ tests/                   # Testing Suite
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_agent_2.py     # Agent 2 (Analyst) tests
â”‚   â”œâ”€â”€ test_onboarding_flow.py # User flow tests
â”‚   â”œâ”€â”€ run_agent_2.py      # Agent execution scripts
â”‚   â””â”€â”€ run_agent_3.py      # Agent testing utilities
â”‚
â”œâ”€â”€ research_notebooks/      # Development & Research
â”‚   â””â”€â”€ nb_1.ipynb          # Analysis notebooks
â”‚
â”œâ”€â”€ images/                  # Static Assets
â”‚   â”œâ”€â”€ cover_image_1.jpg    # App branding images
â”‚   â””â”€â”€ cover_image_2.jpg
â”‚
â”œâ”€â”€ experimentation/         # Development experiments
â”‚
â””â”€â”€ .venv/                   # Virtual environment (local)
```

## ğŸŒ Impact Potential

EcoAction AI moves sustainability from awareness to action through data-driven, personalized guidance:

- **ğŸ¯ Efficiency:** Directs user effort to changes with the highest marginal impact, preventing wasted effort on low-value actions through AI-powered prioritization.

- **ğŸŒ Democratization:** Makes complex carbon footprint data understandable and actionable for anyone, not just sustainability experts, breaking down barriers to climate action.

- **ğŸ“ˆ Scalability:** The AI coach can support millions of users simultaneously, offering a scalable model for behavioral change without human intervention limitations.

- **ğŸ“Š Quantifiable Impact:** Aggregates reduced emissions across the user base, providing concrete measurement of positive environmental contribution with real-time impact tracking.

- **ğŸ”„ Behavioral Change:** Transforms one-time awareness into sustained action through personalized weekly challenges and continuous AI-driven adaptation.

- **ğŸ’¡ Smart Prioritization:** Uses individual lifestyle analysis to identify the most impactful changes specific to each user's circumstances and capabilities.

---

## ğŸš€ Installation & Setup

### Prerequisites
- Python 3.10
- UV package manager (recommended) or pip
- Supabase account
- AIML API key

### Windows Setup

1. **Clone the repository:**
   ```cmd
   git clone https://github.com/yourusername/ecoaction_ai_v01.git
   cd ecoaction_ai_v01
   ```

2. **Install UV package manager:**
   ```cmd
   pip install uv
   ```

3. **Create virtual environment and install dependencies:**
   ```cmd
   uv venv
   .venv\Scripts\activate
   uv sync
   ```

4. **Set up environment variables:**
   ```cmd
   copy .env.example .env
   ```
   Edit `.env` file with your API keys:
   ```
   AI_ML_API_KEY=your_aiml_api_key_here
   SUPABASE_URL=your_supabase_url
   SUPABASE_KEY=your_supabase_anon_key
   ```

5. **Run the application:**
   ```cmd
   streamlit run app.py
   ```

### macOS Setup

1. **Clone the repository:**
   ```bash
   git clone https://github.com/yourusername/ecoaction_ai_v01.git
   cd ecoaction_ai_v01
   ```

2. **Install UV package manager:**
   ```bash
   pip install uv
   ```

3. **Create virtual environment and install dependencies:**
   ```bash
   uv venv
   source .venv/bin/activate
   uv sync
   ```

4. **Set up environment variables:**
   ```bash
   cp .env.example .env
   ```
   Edit `.env` file with your API keys:
   ```
   AI_ML_API_KEY=your_aiml_api_key_here
   SUPABASE_URL=your_supabase_url
   SUPABASE_KEY=your_supabase_anon_key
   ```

5. **Run the application:**
   ```bash
   streamlit run app.py
   ```

### Linux Setup

1. **Clone the repository:**
   ```bash
   git clone https://github.com/yourusername/ecoaction_ai_v01.git
   cd ecoaction_ai_v01
   ```

2. **Install UV package manager:**
   ```bash
   pip install uv
   ```

3. **Create virtual environment and install dependencies:**
   ```bash
   uv venv
   source .venv/bin/activate
   uv sync
   ```

4. **Set up environment variables:**
   ```bash
   cp .env.example .env
   ```
   Edit `.env` file with your API keys:
   ```
   AI_ML_API_KEY=your_aiml_api_key_here
   SUPABASE_URL=your_supabase_url
   SUPABASE_KEY=your_supabase_anon_key
   ```

5. **Run the application:**
   ```bash
   streamlit run app.py
   ```

### Alternative Installation (Without UV)

If you prefer using pip:

```bash
# Create virtual environment
python -m venv .venv

# Activate virtual environment
# Windows:
.venv\Scripts\activate
# macOS/Linux:
source .venv/bin/activate

# Install dependencies
pip install -r requirements.txt  # Generate from pyproject.toml if needed
```

---

## ğŸ§ª Testing

Run the test suite:
```bash
# Activate virtual environment first
pytest tests/

# Run specific agent tests
python tests/test_agent_2.py
python tests/test_onboarding_flow.py
```

## ğŸ“– Usage

1. **Authentication:** Sign up or log in through the authentication page
2. **Onboarding:** Complete the sustainability profile questionnaire
3. **AI Analysis:** Let the three AI agents analyze your data:
   - Agent 1 creates your enriched profile
   - Agent 2 calculates your carbon footprint
   - Agent 3 generates personalized action plans
4. **Dashboard:** View your results, track progress, and access weekly challenges

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸŒŸ Acknowledgments

- CrewAI for the multi-agent framework
- Supabase for the backend infrastructure
- Streamlit for the web interface
- AIML API for LLM capabilities

---

<p align="center">
  <strong>ğŸŒ± Making sustainability personal, actionable, and impactful</strong>
</p>

### Features

- **Authentication**: Secure user authentication with Supabase Auth
- **Dashboard**: Personalized dashboard with action recommendations
- **Progress Tracking**: Track CO2 savings and environmental impact
- **Weekly Reports**: Detailed weekly sustainability reports
- **Community Challenges**: Participate in community sustainability challenges

### Setup and Running the Project on macOS

#### 1. Prerequisites

First, ensure you have Python 3.10+ and `uv` (a Python package manager) installed.

```sh
# Install Python 3.10+ via Homebrew if you don't have it
brew install python

# Install uv
pip install uv
```

#### 2. Project Setup

Navigate to your project directory in the terminal and create a virtual environment, then install the required dependencies.

```sh
# Create a virtual environment
uv venv

# Activate the virtual environment
source .venv/bin/activate

# Install dependencies from pyproject.toml
uv sync
```

#### 3. Configure Environment Variables

Your application requires API keys for Supabase and an AI service. Create a `.env` file in the root of your project directory.

```
SUPABASE_URL="your_supabase_url_here"
SUPABASE_KEY="your_supabase_anon_key_here"
AI_ML_API_KEY="your_aiml_api_key_here"
```

You will need to get these credentials from your Supabase project settings and the AI/ML API provider you are using.

#### 4. Set Up the Database

The application uses Supabase for the backend. You will need to:
1.  Create a project on [Supabase](https://supabase.com/).
2.  Use the SQL scripts in your `data_model` directory, like `data_model/sql_scripts_1.sql`, to set up the necessary tables (e.g., `users`) in the Supabase SQL Editor.

#### 5. Run the Application

Once the setup is complete, you can run the Streamlit application.

```sh
streamlit run app.py
```

This will start the web server, and you can access the application in your browser at the local URL provided in the terminal output.
